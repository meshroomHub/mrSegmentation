__version__ = "0.3"

import os
from pathlib import Path

from meshroom.core import desc
from meshroom.core.utils import VERBOSE_LEVEL

class ImageSegmentationBoxNodeSize(desc.MultiDynamicNodeSize):
    def computeSize(self, node):
        if node.attribute(self._params[0]).isLink:
            return node.attribute(self._params[0]).inputLink.node.size

        from pathlib import Path

        input_path_param = node.attribute(self._params[0])
        extension_param = node.attribute(self._params[1])
        input_path = input_path_param.value
        extension = extension_param.value
        include_suffixes = [extension.lower(), extension.upper()]

        size = 1
        if Path(input_path).is_dir():
            import itertools
            image_paths = list(itertools.chain(*(Path(input_path).glob(f'*.{suffix}') for suffix in include_suffixes)))
            size = len(image_paths)
        
        return size
        
class ImageSegmentationBox(desc.Node):
    size = ImageSegmentationBoxNodeSize(['input', 'extensionIn'])
    gpu = desc.Level.INTENSIVE
    parallelization = desc.Parallelization(blockSize=50)

    category = "Utils"
    documentation = """
Based on the Segment Anything model, the node generates a binary mask from a set of bounding boxes and points corresponding to clicks inside/outside.
The bounding boxes can be provided through a json file as the one generated by the imageDetectionPrompt node or through a nk file storing a Tracker4 Nuke tracker.
Points can be provided through the same kind of Nuke tracker file.

The only requirement for the tracker file is about the tracks names. To be considered, a track name must contain at least one of the following patterns:
 * "In_", "Out_", "bboxT_" or "bboxS".
 * "In_": The track curve will be considered as Clicks inside the object to segment.
 * "Out_": The track curve will be considered as Clicks outside the object to segment.
 * "bboxT_": The tracking bounding box will be used.
 * "bboxS_": The searching bounding box will be used.

The bounding boxes coming from the Nuke tracker are appended to the ones coming from the json file if any.
In case neither tracker nor json file is available, the model is applied on the full image.
In case bounding boxes and clicks are provided, only clicks inside bounding boxes are considered.
"""

    inputs = [
        desc.File(
            name="input",
            label="Input",
            description="Folder or SfMData file.",
            value="",
        ),
        desc.ChoiceParam(
            name="extensionIn",
            label="Input File Extension",
            description="Input image file extension.\n"
                        "Considered only if input is a folder.",
            value="exr",
            values=["exr", "png", "jpg"],
            exclusive=True,
            group="",  # remove from command line params
            enabled=lambda node: Path(node.input.value).is_dir(),
        ),
        desc.File(
            name="bboxFolder",
            label="BBoxes Folder",
            description="JSON file containing prompting bounding boxes.",
            value="",
        ),
        desc.File(
            name="nukeTracker",
            label="Nuke Tracker",
            description="Nuke file .nk containing a tracker node.",
            value="",
        ),
        desc.File(
            name="segmentationModelPath",
            label="Segmentation Model",
            description="Weights file for the segmentation model.",
            value="${RDS_SEGMENTATION_MODEL_PATH}",
        ),
        desc.BoolParam(
            name="maskInvert",
            label="Invert Masks",
            description="Invert mask values. If selected, the pixels corresponding to the mask will be set to 0 instead of 255.",
            value=False,
        ),
        desc.BoolParam(
            name="useGpu",
            label="Use GPU",
            description="Use GPU for computation if available.",
            value=True,
            invalidate=False,
        ),
        desc.BoolParam(
            name="keepFilename",
            label="Keep Filename",
            description="Keep the filename of the inputs for the outputs.",
            value=False,
            enabled=lambda node: not Path(node.input.value).is_dir(),
        ),
        desc.ChoiceParam(
            name="extensionOut",
            label="Output File Extension",
            description="Output image file extension.\n"
                        "If unset, the output file extension will match the input's if possible.",
            value="exr",
            values=["exr", "png", "jpg"],
            exclusive=True,
            group="",  # remove from command line params
        ),
        desc.BoolParam(
            name="outputBboxImage",
            label="Output Bounding Box Image",
            description="Write source image with bounding boxes and clicks In/Out baked in.",
            value=False,
        ),
        desc.ChoiceParam(
            name="verboseLevel",
            label="Verbose Level",
            description="Verbosity level (fatal, error, warning, info, debug).",
            value="info",
            values=VERBOSE_LEVEL,
            exclusive=True,
        ),
    ]

    outputs = [
        desc.File(
            name="output",
            label="Masks Folder",
            description="Output path for the masks.",
            value="{nodeCacheFolder}",
        ),
        desc.File(
            name="masks",
            label="Masks",
            description="Generated segmentation masks.",
            semantic="image",
            value=lambda attr: "{nodeCacheFolder}/" + ("<FILESTEM>" if attr.node.keepFilename.value else "<VIEW_ID>") + "." + attr.node.extensionOut.value,
            group="",
        ),
        desc.File(
            name="bboxes",
            label="BBoxes",
            description="Images with retained bounded boxes and clicks In/Out baked in.",
            semantic="image",
            value=lambda attr: "{nodeCacheFolder}/bboxes_" + ("<FILESTEM>" if attr.node.keepFilename.value else "<VIEW_ID>") + ".jpg",
            enabled=lambda node: node.outputBboxImage.value,
            group="",
        ),
    ]

    def resolvedPaths(self, input_path, extensionIn, outDir, keepFilename, extensionOut):
        from pyalicevision import sfmData
        from pyalicevision import sfmDataIO
        from pathlib import Path
        import itertools

        include_suffixes = [extensionIn.lower(), extensionIn.upper()]
        paths = {}
        if Path(input_path).is_dir():
            input_filepaths = sorted(itertools.chain(*(Path(input_path).glob(f'*.{suffix}') for suffix in include_suffixes)))
            for frameId, inputFile in enumerate(input_filepaths):
                outputFileMask = os.path.join(outDir, Path(inputFile).stem + "." + extensionOut)
                outputFileBoxes = os.path.join(outDir, "bboxes_" + Path(inputFile).stem + ".jpg")
                paths[str(inputFile)] = (outputFileMask, outputFileBoxes, frameId, 'not_a_view')
        elif Path(input_path).suffix.lower() in [".sfm", ".abc"]:
            if Path(input_path).exists():
                dataAV = sfmData.SfMData()
                if sfmDataIO.load(dataAV, input_path, sfmDataIO.ALL) and os.path.isdir(outDir):
                    views = dataAV.getViews()
                    for id, v in views.items():
                        inputFile = v.getImage().getImagePath()
                        frameId = v.getFrameId()
                        if keepFilename:
                            outputFileMask = os.path.join(outDir, Path(inputFile).stem + "." + extensionOut)
                            outputFileBoxes = os.path.join(outDir, "bboxes_" + Path(inputFile).stem + ".jpg")
                        else:
                            outputFileMask = os.path.join(outDir, str(id) + "." + extensionOut)
                            outputFileBoxes = os.path.join(outDir, "bboxes_" + str(id) + ".jpg")
                        paths[inputFile] = (outputFileMask, outputFileBoxes, frameId, str(id))

        return paths

    def processChunk(self, chunk):
        import json
        from segmentationRDS import image, segmentation, nktracker
        import numpy as np
        import torch
        from pyalicevision import image as avimg

        processor = None
        try:
            chunk.logManager.start(chunk.node.verboseLevel.value)

            if not chunk.node.input:
                chunk.logger.warning("Nothing to segment")
                return
            if not chunk.node.output.value:
                return
            if not chunk.node.nukeTracker.value and not chunk.node.bboxFolder.value:
                chunk.logger.warning("No bounding boxes and no tracker info, the full image will be segmented")
            if chunk.node.nukeTracker.value:
                tracker = nktracker.nkTracker(chunk.node.nukeTracker.value)
            else:
                tracker = None

            chunk.logger.info("Chunk range from {} to {}".format(chunk.range.start, chunk.range.last))

            outFiles = self.resolvedPaths(chunk.node.input.value, chunk.node.extensionIn.value, chunk.node.output.value, chunk.node.keepFilename.value, chunk.node.extensionOut.value)

            if not os.path.exists(chunk.node.output.value):
                os.mkdir(chunk.node.output.value)

            processor = segmentation.SegmentAnything(SAM_CHECKPOINT_PATH = chunk.node.segmentationModelPath.evalValue,
                                                     useGPU = chunk.node.useGpu.value)

            bboxDictFromShape = {}
            if chunk.node.bboxFolder.value:
                for file in os.listdir(chunk.node.bboxFolder.value):
                    if file.endswith("shapes.json"):
                        with open(os.path.join(chunk.node.bboxFolder.value,file)) as shapeFile:
                            shapes = json.load(shapeFile)
                            for shape in shapes["shapes"]:
                                for key in shape["observations"]:
                                    xc = shape["observations"][key]["center"]["x"]
                                    yc = shape["observations"][key]["center"]["y"]
                                    w = shape["observations"][key]["size"]["width"]
                                    h = shape["observations"][key]["size"]["height"]
                                    bb = [xc - w/2, yc - h/2, xc + w/2, yc + h/2]
                                    if key in bboxDictFromShape:
                                        bboxDictFromShape[key].append(bb)
                                    else:
                                        bboxDictFromShape[key] = [bb]

            metadata_deep_model = {}
            metadata_deep_model["Meshroom:mrSegmentation:DeepModelName"] = "SegmentAnything"
            metadata_deep_model["Meshroom:mrSegmentation:DeepModelVersion"] = "sam_vit_h_4b8939"

            for k, (iFile, oFile) in enumerate(outFiles.items()):
                if k >= chunk.range.start and k <= chunk.range.last:
                    img, h_ori, w_ori, PAR, orientation = image.loadImage(iFile, True)
                    frameId = oFile[2]

                    chunk.logger.info("frameId: {} - {}".format(frameId, iFile))

                    bboxes = []
                    if not chunk.node.nukeTracker.value and not chunk.node.bboxFolder.value:
                        bboxes = [[0, 0, img.shape[1] - 1, img.shape[0] - 1]]
                    elif chunk.node.bboxFolder.value:
                        bboxes = bboxDictFromShape[iFile if oFile[3] == "not_a_view" else oFile[3]]

                    clicksIn = []
                    clicksOut = []
                    if tracker is not None:
                        data = tracker.getDataAtFrame(frameId, img.shape[0], PAR)
                        trackNames = tracker.getTrackNames()
                        for trackName in trackNames:
                            if data[trackName][0][0] is not None:
                                if trackName.find("In_") != -1:
                                    clicksIn.append(data[trackName][0])
                                elif trackName.find("Out_") != -1:
                                    clicksOut.append(data[trackName][0])
                                if trackName.find("bboxT_") != -1:
                                    bboxes.append(data[trackName][1])
                                if trackName.find("bboxS_") != -1:
                                    bboxes.append(data[trackName][2])

                    chunk.logger.debug("Clicks In: {}".format(clicksIn))
                    chunk.logger.debug("Clicks Out: {}".format(clicksOut))
                    chunk.logger.debug("bboxes: {}".format(bboxes))

                    mask = processor.process(image = img,
                                             bboxes = np.asarray(bboxes),
                                             clicksIn = clicksIn,
                                             clicksOut = clicksOut,
                                             invert = chunk.node.maskInvert.value,
                                             verbose = False)

                    optWrite = avimg.ImageWriteOptions()
                    if Path(oFile[0]).suffix.lower() == ".exr":
                        optWrite.toColorSpace(avimg.EImageColorSpace_NO_CONVERSION)
                        optWrite.exrCompressionMethod(avimg.EImageExrCompression_stringToEnum("DWAA"))
                        optWrite.exrCompressionLevel(300)
                    else:
                        optWrite.toColorSpace(avimg.EImageColorSpace_SRGB)

                    image.writeImage(oFile[0], mask, h_ori, w_ori, orientation, PAR, metadata_deep_model, optWrite)

                    if chunk.node.outputBboxImage.value:
                        bbox_img = img.copy()
                        for bbox in bboxes:
                            bbox_img = image.addRectangle(bbox_img, bbox, (0, 255, 0))
                        for click in clicksIn:
                            bbox_img = image.addPoint(bbox_img, click, (0, 255, 0))
                        for click in clicksOut:
                            bbox_img = image.addPoint(bbox_img, click, (255, 0, 0))
                        image.writeImage(oFile[1], bbox_img, h_ori, w_ori, orientation, PAR)

        finally:
            del processor
            torch.cuda.empty_cache()
            chunk.logManager.end()
